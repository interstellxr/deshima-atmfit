{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XE0jLxcxsPSKz7beLYkdosHsiaCNJzUl",
      "authorship_tag": "ABX9TyOj03F/EnJss/WFgX74AIna",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/interstellxr/deshima-atmfit/blob/main/atmfit-v1.0.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BTtHOikDAqB",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title Import libraries & dependencies\n",
        "\n",
        "# standard library\n",
        "from typing import Any, Tuple\n",
        "\n",
        "# dependencies\n",
        "import casatools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for xarray\n",
        "import pandas as pd\n",
        "import decode as dc\n",
        "import xarray as xr\n",
        "\n",
        "# for the fitting function\n",
        "from scipy.optimize import least_squares\n",
        "from scipy.interpolate import interp1d\n",
        "from astropy.io import fits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ATM model (Pardo et al. 2001)\n",
        "\n",
        "def get_tau(\n",
        "    f_min: float,\n",
        "    f_max: float,\n",
        "    f_step: float,\n",
        "    pwv: float,\n",
        "    **atm_params: Any,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Compute of zenith opacities at given frequencies.\n",
        "\n",
        "    Args:\n",
        "        f_min: Minimum frequency (in units of Hz).\n",
        "        f_max: Maximum frequency (in units of Hz).\n",
        "        f_step: Frequency step (in units of Hz).\n",
        "        pwv: Precipitable water vapor (in units of mm).\n",
        "        atm_params: Parameters fo the ATM model.\n",
        "\n",
        "    Returns:\n",
        "        freq: Array of frequencies (in units of Hz).\n",
        "        tau: Array of zenith opacities at the frequencies.\n",
        "\n",
        "    \"\"\"\n",
        "    at = casatools.atmosphere()\n",
        "    qa = casatools.quanta()\n",
        "\n",
        "    f_cent = qa.quantity((f_min + f_max) / 2, \"Hz\")\n",
        "    f_width = qa.quantity(f_max - f_min + f_step, \"Hz\")\n",
        "    f_step = qa.quantity(f_step, \"Hz\")\n",
        "    pwv = qa.quantity(pwv, \"mm\")\n",
        "\n",
        "    at.initAtmProfile(**atm_params)\n",
        "    at.initSpectralWindow(1, f_cent, f_width, f_step)\n",
        "    at.setUserWH2O(pwv)\n",
        "\n",
        "    freq = qa.convert(at.getSpectralWindow(), \"Hz\")[\"value\"]\n",
        "    tau = at.getDryOpacitySpec()[1] + at.getWetOpacitySpec()[1]['value']\n",
        "\n",
        "    return freq, tau"
      ],
      "metadata": {
        "id": "QOMJ7wojDVnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download filter responses (DDB)\n",
        "\n",
        "! gdown \"1gE0IJzlJpN9xrCqXSOvg7AJw1GPAxYhK\"\n",
        "ddb = fits.open(\"ddb_20231123.fits.gz\")"
      ],
      "metadata": {
        "id": "zA73z83K-hDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main function\n",
        "\n",
        "def ATM_fit(da, pwv0, dt, *ranges_weights): # Obligatory input : DEMS (xarray.DataArray)\n",
        "# Optional inputs : initial PWV value (float), time step (int), weighted frequency ranges (tuples of floats : (fmin, fmax, weight))\n",
        "\n",
        "\n",
        "    ## ERROR HANDLING ##\n",
        "\n",
        "    ranges = []\n",
        "    weights = []\n",
        "\n",
        "    for r_w in ranges_weights:\n",
        "        if len(r_w) != 3:\n",
        "            raise ValueError(\"Each range must contain minimum and maximum frequencies and have a corresponding weight.\")\n",
        "        ranges.append(r_w[0:2])\n",
        "        weights.append(r_w[-1])\n",
        "\n",
        "    if not isinstance(da, xr.DataArray):\n",
        "        raise TypeError(f\"Argument '{da}' must be an xarray DataArray, got {type(da).__name__} instead.\")\n",
        "\n",
        "    if not isinstance(ddb, fits.HDUList):\n",
        "        raise TypeError(f\"Argument '{ddb}' must be a .fits, got {type(ddb).__name__} instead.\")\n",
        "\n",
        "    for k,frange in enumerate(ranges):\n",
        "        w = weights[k]\n",
        "        for arg in [frange[0], frange[1], pwv0, w]:\n",
        "            if arg is not None and not isinstance(arg, (int, float)):\n",
        "                raise TypeError(f\"Argument '{arg}' must be a number, got {type(arg).__name__} instead.\")\n",
        "            if arg is not None and arg is not pwv0 and arg is not w and arg <= 0:\n",
        "                raise ValueError(f\"Argument '{arg}' must be a strictly positive number.\")\n",
        "            if (arg is pwv0 or arg is w) and arg is not None and arg < 0:\n",
        "                raise ValueError(f\"Argument '{arg}' must be a positive number or null.\")\n",
        "\n",
        "        if k != 0 and k!= len(ranges)-1:\n",
        "            if frange[0] is None or frange[1] is None:\n",
        "                raise ValueError(f\"Both fmin and fmax must be specified.\")\n",
        "\n",
        "        if frange[0] is not None and frange[1] is not None:\n",
        "            if frange[0] > frange[1]:\n",
        "                raise ValueError(f\"fmin must be less than or equal to fmax.\")\n",
        "\n",
        "    if dt is not None and dt >= len(da.time.values):\n",
        "        print(\"Warning: dt is greater than time series length, which might not be intended.\")\n",
        "\n",
        "    if dt is not None and ( not isinstance(dt, int) or dt<=0 ) :\n",
        "        raise TypeError(f\"dt must be a positive integer, got {type(dt).__name__} instead.\")\n",
        "\n",
        "\n",
        "    ## CREATE ATM PARAMETERS ##\n",
        "\n",
        "    def get_first_non_nan(arr, default):\n",
        "        for value in arr:\n",
        "            if not np.isnan(value):\n",
        "                return value\n",
        "        return default\n",
        "\n",
        "    default_pressure = 570  # mbar\n",
        "    default_humidity = 20  # percent\n",
        "    default_temperature = 0  # C\n",
        "\n",
        "    pressure_value = get_first_non_nan(da.pressure.values, default_pressure)\n",
        "    humidity_value = get_first_non_nan(da.humidity.values, default_humidity)\n",
        "    temperature_value = get_first_non_nan(da.temperature.values, default_temperature) + 273.15 # convert to Kelvin (DEMS temperatures are in C)\n",
        "\n",
        "    atm_params = {\n",
        "        'atmType': 1,\n",
        "        'humidity': humidity_value,\n",
        "        'temperature': f'{temperature_value} K',\n",
        "        'altitude': '4860 m',\n",
        "        'pressure': f'{pressure_value} mbar',\n",
        "        'h0': '2.0 km',\n",
        "    }\n",
        "\n",
        "\n",
        "    ## LOAD DATA ##\n",
        "\n",
        "    T_atmos = temperature_value\n",
        "\n",
        "    freq = da.d2_mkid_frequency.values\n",
        "    freq_unsorted = freq\n",
        "\n",
        "    kidfilt = ddb[\"KIDFILT\"] # fits file\n",
        "    masterid = kidfilt.data[\"masterid\"] # channel IDs of filter response functions (more than in DEMS)\n",
        "    nu = kidfilt.data[\"Raw Toptica F\"] # corresponding frequencies (same for all IDs normally)\n",
        "    R = kidfilt.data[\"Raw df resp.\"] # corresponding responses (y data)\n",
        "\n",
        "    common_indices = np.where(np.isin(masterid, da.chan.values))[0] # find common channels\n",
        "    nu = nu[common_indices]\n",
        "    R = R[common_indices]\n",
        "\n",
        "    sorted_indices = np.argsort(freq) # sort frequencies (just for simplicity in the following lines)\n",
        "    freq = freq[sorted_indices]\n",
        "    nu = nu[sorted_indices]\n",
        "    R = R[sorted_indices]\n",
        "\n",
        "    for range in ranges: # check given ranges are subsets of global range\n",
        "        fmin = range[0]\n",
        "        fmax = range[1]\n",
        "        if (fmin is not None and fmin < freq[0]) :\n",
        "            raise ValueError(f\"fmin must be within the frequency range.\")\n",
        "\n",
        "        if (fmax is not None and fmax > freq[-1]) :\n",
        "            raise ValueError(f\"fmax must be within the frequency range.\")\n",
        "\n",
        "    N = len(freq)-1\n",
        "    m = freq[0]\n",
        "    M = freq[-1]\n",
        "    step = (freq[-1] - freq[0])/N # we want a step as close to the data as possible\n",
        "\n",
        "    # set default values to arguments\n",
        "    if pwv0 is None:\n",
        "        init_PWV = 1.0\n",
        "    else :\n",
        "        init_PWV = pwv0\n",
        "    if dt is None:\n",
        "        time_step = 1\n",
        "    else :\n",
        "        time_step = dt\n",
        "    if w is None:\n",
        "        W = 1\n",
        "    else :\n",
        "        W = w\n",
        "\n",
        "\n",
        "    ## FITTING FUNCTION ##\n",
        "\n",
        "    def Tb_fit(t,freq,fit_T_atm=True, T_atm=None): # take in boolean to see if we should fit for T_atm (only for t==0)\n",
        "\n",
        "\n",
        "        ## LOAD DATA AND HANDLE NANS ##\n",
        "\n",
        "        Tb = da[t,:].values\n",
        "        Tb= Tb[sorted_indices]\n",
        "        valid_indices = np.where(~np.isnan(Tb))\n",
        "        Tb_valid = Tb[valid_indices]\n",
        "        freq_valid = freq[valid_indices]\n",
        "\n",
        "        if not np.isnan(da.secz.values[t]):\n",
        "            airmass = da.secz.values[t]\n",
        "\n",
        "        else : # airmass is the last non nan value of secz before t or first non nan value after t (whichever is closest to t)\n",
        "            before_t_idx = np.where(~np.isnan(da.secz_values[:t]))[0] # last non nan before t\n",
        "            if before_t_idx.size > 0:\n",
        "                last_idx = before_t_idx[-1]\n",
        "                last = da.secz_values[last_idx]\n",
        "            else:\n",
        "                last_idx = None\n",
        "                last = np.nan\n",
        "\n",
        "            after_t_idx = np.where(~np.isnan(da.secz_values[t+1:]))[0] + t + 1 # first non nan after t\n",
        "            if after_t_idx.size > 0:\n",
        "                first_idx = after_t_idx[0]\n",
        "                first = da.secz_values[first_idx]\n",
        "            else:\n",
        "                first_idx = None\n",
        "                first = np.nan\n",
        "\n",
        "            if last_idx is not None and first_idx is not None:\n",
        "                if (t - last_idx) <= (first_idx - t): # determine which is closest\n",
        "                    airmass = last\n",
        "                else:\n",
        "                    airmass = first\n",
        "            elif last_idx is not None:\n",
        "                airmass = last\n",
        "            elif first_idx is not None:\n",
        "                airmass = first_idx\n",
        "            else:\n",
        "                airmass = 1 # default if all are NaNs\n",
        "\n",
        "\n",
        "        # create an empty array with the same shape as Tb : useful for ouput (we want to keep NaNs to match input)\n",
        "        empty_Tb = np.empty_like(Tb, dtype = 'float')\n",
        "        empty_Tb[np.isnan(Tb)] = np.nan\n",
        "\n",
        "        # R is an array of response functions (themselves arrays with x values being frequencies)\n",
        "        # so we iterate over the responses and interpolate to match frequencies\n",
        "        def interpolate_responses(frequencies, responses, freq_valid):\n",
        "            return np.array([interp1d(freq, resp, kind='linear', fill_value=\"extrapolate\")(freq_valid) for freq, resp in zip(frequencies, responses)])\n",
        "\n",
        "        filter_responses = interpolate_responses(nu[valid_indices], R[valid_indices], freq_valid)\n",
        "\n",
        "\n",
        "        ## CONVERT OPACITY GIVEN BY MODEL TO SKY BRIGHTNESS TEMPERATURE ##\n",
        "\n",
        "        def tau_to_T(params):\n",
        "            pwv, T_atm_ = params if fit_T_atm else (params[0], T_atm)\n",
        "            temp, tau = get_tau(m*1e9, M*1e9, step*1e9, pwv, **atm_params)\n",
        "            tau = interp1d(temp[valid_indices], tau[valid_indices], kind='linear', bounds_error=False, fill_value=\"extrapolate\")(freq_valid*1e9)\n",
        "            T_model = T_atm_ * (1 - np.exp(-tau*airmass))\n",
        "\n",
        "            norm = np.sum(filter_responses, axis=0)\n",
        "            filtered_T_model = np.sum([T_model * resp for resp in filter_responses], axis=0) / norm\n",
        "\n",
        "            return filtered_T_model\n",
        "\n",
        "\n",
        "        ## RESIDUAL FUNCTION ##\n",
        "\n",
        "        def diff(params, w):\n",
        "            return abs(Tb_valid - tau_to_T(params)) * w\n",
        "\n",
        "        weights_array = np.ones_like(Tb_valid)\n",
        "\n",
        "        for r, W in zip(ranges,weights): # assign weights\n",
        "            if r[0] is None and r[1] is not None:\n",
        "                mask = (freq_valid >= freq_valid[0]) & (freq_valid <= r[1])\n",
        "            if r[1] is None and r[0] is not None:\n",
        "                mask = (freq_valid >= r[0]) & (freq_valid <= freq_valid[-1])\n",
        "            if r[0] is None and r[1] is None:\n",
        "                mask = (freq_valid >= freq_valid[0]) & (freq_valid <= freq_valid[-1])\n",
        "            if r[0] is not None and r[1] is not None:\n",
        "                mask = (freq_valid >= r[0]) & (freq_valid <= r[1])\n",
        "            weights_array[np.where(mask)] = W\n",
        "\n",
        "\n",
        "        ## LEAST SQUARES FIT ##\n",
        "\n",
        "        init_params = [init_PWV, T_atm] if fit_T_atm else [init_PWV]\n",
        "        bounds = ([0, 200], [np.inf, 300]) if fit_T_atm else ([0], [np.inf]) # bounds for PWV and T_atm\n",
        "        result = least_squares(diff,init_params,loss='huber', kwargs={'w': weights_array}, bounds = bounds)\n",
        "\n",
        "        optim_PWV, optim_T_atm = result.x if fit_T_atm else (result.x[0], T_atm)\n",
        "\n",
        "        J = result.jac\n",
        "        cov = np.linalg.inv(J.T.dot(J))\n",
        "        std = np.sqrt(np.diagonal(cov))\n",
        "        PWV_std, T_atm_std = std if fit_T_atm else (std[0], 0)\n",
        "\n",
        "        Tmodel = tau_to_T(result.x)\n",
        "\n",
        "        # Re-insert NaN positions\n",
        "        k=0\n",
        "        for i,el in enumerate(empty_Tb):\n",
        "              if not np.isnan(el):\n",
        "                  empty_Tb[i] = Tmodel[k]\n",
        "                  k+=1\n",
        "\n",
        "        unsorted_indices = np.argsort(sorted_indices) # unsort indices to match input data array\n",
        "        empty_Tb = empty_Tb[unsorted_indices]\n",
        "\n",
        "        return empty_Tb, optim_PWV, optim_T_atm, PWV_std, T_atm_std # return unsorted and invalid (with NaNs) Tb_model and optimized PWV and optimized T_atm with errors\n",
        "\n",
        "\n",
        "    ## LOOP OVER TIME ##\n",
        "\n",
        "    init_time = 0\n",
        "    _, _, initial_T_atm, _, initial_T_atm_std = Tb_fit(init_time, freq, fit_T_atm=True, T_atm=T_atmos)\n",
        "\n",
        "    time_values=pd.Series(da.time.values[0:len(da.time):time_step])\n",
        "\n",
        "    Tb_model_array = []\n",
        "    optim_PWV_array = np.array([])\n",
        "    optim_T_atm_array = np.array([])\n",
        "    PWV_std_array = np.array([])\n",
        "    T_atm_std_array = np.array([])\n",
        "\n",
        "    for time_str in time_values:\n",
        "        t = np.where(da.time.values == time_str)[0][0]\n",
        "        T, PWV, T_ATM, PWV_std, _ = Tb_fit(t,freq, fit_T_atm=False,T_atm=initial_T_atm)\n",
        "        Tb_model_array.append(T)\n",
        "        optim_PWV_array = np.append(optim_PWV_array,PWV)\n",
        "        optim_T_atm_array = np.append(optim_T_atm_array, T_ATM)\n",
        "        PWV_std_array = np.append(PWV_std_array, PWV_std)\n",
        "        T_atm_std_array = np.append(T_atm_std_array, initial_T_atm_std)\n",
        "\n",
        "\n",
        "    ## CREATE THE OUTPUT DATA ARRAY ##\n",
        "\n",
        "    new_da = da\n",
        "    new_da.values = np.array(Tb_model_array)\n",
        "    new_da.assign_coords(PWV=(\"time\",optim_PWV_array))\n",
        "    new_da.assign_coords(T_atm=(\"time\",optim_T_atm_array))\n",
        "    new_da.assign_coords(T_atm_std=(\"time\",T_atm_std_array))\n",
        "    new_da.assign_coords(PWV_std=(\"time\",PWV_std_array))\n",
        "\n",
        "    new_da['PWV'].attrs['long name'] = 'Precipitable Water Vapor derived from ATM model'\n",
        "    new_da['PWV'].attrs['units'] = 'mm'\n",
        "\n",
        "    new_da['T_atm'].attrs['long_name'] = 'Atmospheric Temperature derived from ATM model'\n",
        "    new_da['T_atm'].attrs['units'] = 'K'\n",
        "\n",
        "    new_da['PWV_std'].attrs['long_name'] = 'Standard deviation of PWV derived from ATM model'\n",
        "    new_da['PWV_std'].attrs['units'] = 'mm'\n",
        "\n",
        "    new_da['T_atm_std'].attrs['long_name'] = 'Standard deviation of T_atm derived from ATM model'\n",
        "    new_da['T_atm_std'].attrs['units'] = 'K'\n",
        "\n",
        "    return new_da"
      ],
      "metadata": {
        "id": "50luQNYRDXon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}